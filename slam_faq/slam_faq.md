# SLAM FAQ

-----

[TOC]

# Computer Vision

# DIP

Q: 常用的边缘检测算子和优缺点

边缘检测一般分为三步，分别是滤波、增强、检测。基本原理都是用高斯滤波器进行去噪，之后在用卷积内核寻找像素梯度。常用有三种算法：canny算子，sobel算子，laplacian算子

* canny算子：一种完善的边缘检测算法，抗噪能力强，用高斯滤波平滑图像，用一阶偏导的有限差分计算梯度的幅值和方向，对梯度幅值进行非极大值抑制，采用双阈值检测和连接边缘。

* sobel算子：一阶导数算子，引入局部平均运算，对噪声具有平滑作用，抗噪声能力强，计算量较大，但定位精度不高，得到的边缘比较粗，适用于精度要求不高的场合。

* laplacian算子：二阶微分算子，具有旋转不变性，容易受噪声影响，不能检测边缘的方向，一般不直接用于检测边缘，而是判断明暗变化。


## 相机模型

Q: 解释相机内外参数

* 相机内参包括焦距fx，fy，cx，cy，径向畸变系数k1,k2,k3，切向畸变系数p1,p2，其中内参一般来说是不会改变，但是当使用可变焦距镜头时每次改变焦距需要重新标定内参

* 当图像裁剪时内参cx，cy会发生改变，比如图像从8*8变成4*4时，cx，cy需要除以2

* 一般标定工业相机时只需要得到畸变系数k1，k2即可，对于畸变系数较大的鱼眼相机需要得到k3，p1，p2

* 相机外参分为旋转矩阵R和平移矩阵t，旋转矩阵和平移矩阵共同描述了如何把点从世界坐标系转换到摄像机坐标系

## 深度相机

Q: 单目，双目，深度相机对比

* 单目：成本低，搭建简单，单目相机有尺度不确定性，需要专门初始化

* 双目：不需要专门初始化，能够计算深度，基线距离越大，测量距离越远，可以用于室内和室外，标定较为复杂，视差计算比较消耗资源

* 深度：测量范围窄，噪声大，易受日光干扰，无法测量透射材料，主要用于室内


# INS/GNSS

# Kinematics

Q: SLAM中为什么用李群李代数？

slam中一个关键问题之一就是求解相机的位姿，人们找了很多以相机位姿为变量的误差函数，比如光度误差，重投影误差等等，希望使得误差最小，进而求得比较准确的相机位姿。比如对重投影误差，我们想要寻找一个最佳的位姿T，使得把每次观测的误差累加得到的整体误差J（T）最小化。优化方法一般都采用迭代优化的方法，每次迭代都更新一个位姿的增量delta，使得目标函数最小。这个delta就是通过误差函数J（T）对T微分得到的。T中的旋转矩阵R自身是带有约束的，它是正交矩阵并且行列式为1。如果把它们作为优化变量，会引入额外的约束，使优化变得困难。通过李群-李代数间的转换关系，就可以把这个问题变成无约束的优化问题。   

更详细点说。群是一种集合加上一种运算的代数结构，李群是具有连续光滑性质的群。旋转矩阵和乘法就构成了旋转矩阵群SO3，变换矩阵和乘法构成了变换矩阵群SE3。SO3和SE3空间对加法计算并不封闭，也就是说任意两个变换矩阵相加后并不是一个变换矩阵，这样就没有办法按照导数的定义进行求导（如对一个空间点进行旋转然后对该旋转求导）。李代数对应李群的切空间，它描述了李群局部的导数。李代数是由向量组成的，而向量是对加法封闭的。这样我们就可以通过对李代数求导来间接的对变换（或旋转）矩阵求导了。对于求导一般有两种方法，一种是用李代数表示姿态，然后对李代数求导；一种是对李群左乘或右乘一个微小扰动，然后对该扰动对应的李代数求导。前者会含有形式比较复杂的雅可比矩阵，故一般用后者进行计算。

旋转矩阵自身是带有约束的，正交且行列式为1，他们作为优化变量时，会引入额外的约束，时优化变的困难，通过李群李代数的转换关系，把位姿估计变成无约束的优化问题。


2. 为什么要引入李群李代数

旋转矩阵自身是带有约束的，正交且行列式为1，他们作为优化变量时，会引入额外的约束，时优化变的困难，通过李群李代数的转换关系，把位姿估计变成无约束的优化问题。

2. 单目相机，F和H矩阵有何不同，E和F矩阵有何不同，只旋转不平移能不能求F，只旋转不平移能不能求H

$$
E = t \times R \\
F = K^{-T} E K^{-1} \\
H = R - t * \frac{nT}{d}
$$

在相机只有旋转而没有平移的情况，此时t为0，E也将为0，导致无法求解R，这时可以使用单应矩阵H求旋转，但仅有旋转，无法三角化求深度。

7. 什么是极限约束

所谓极线约束就是说同一个点在两幅图像上的映射，已知左图映射点p1，那么右图映射点p2一定在相对于p1的极线上，这样可以减少待匹配的点数量。（画图解释）

3. 描述PnP

Perspective-n-Points, PnP(P3P)提供了一种解决方案，它是一种由3D-2D的位姿求解方式，即需要已知匹配的3D点和图像2D点。目前遇到的场景主要有两个，其一是求解相机相对于某2维图像/3维物体的位姿；其二就是SLAM算法中估计相机位姿时通常需要PnP给出相机初始位姿。

在场景1中，我们通常输入的是物体在世界坐标系下的3D点以及这些3D点在图像上投影的2D点，因此求得的是相机坐标系相对于世界坐标系(Twc)的位姿

在场景2中，通常输入的是上一帧中的3D点（在上一帧的相机坐标系下表示的点）和这些3D点在当前帧中的投影得到的2D点，所以它求得的是当前帧相对于上一帧的位姿变换，如图所示：

两种情况本质上是相同的，都是基于已知3D点和对应的图像2D点求解相机运动的过程。

# State Estimation

## Optimization

5. 描述下GN、LM方法

（1） GN：线搜索

将f（x）进行一节泰勒展开，最后求解

线性方程H△x=b；

用JT*J近似H矩阵，省略H复杂的计算

过程；

稳定性差，可能不收敛；

（2） LM：信赖区域；

求解线性方程(H+λI)△x=b；

提供更稳定，更准确的增量


8. 一阶梯度下降，G-N和L-M三种方法的关系

(H+λI)△x=b

当λ= 0时，L-M等于G-N；

当λ= ∞时，L-M等于一阶梯度下降

L-M的好处就在于：如果下降的太快，使用较小的λ，如果下降的太慢，使用较大的λ


9. 为什么SLAM中常用L-M？

G-N中的H矩阵可能为奇异矩阵或者病态矩阵，导致算法不收敛。而且当步长较大时，也无法保证收敛性，所以采用L-M求解增量方程，但是它的收敛速度可能较慢。


## 去外点

10. 介绍RANSAC算法

RANSAC算法的基本假设是样本中包含正确数据(inliers，可以被模型描述的数据)，也包含异常数据(outliers，偏离正常范围很远、无法适应数学模型的数据)，即数据集中含有噪声。这些异常数据可能是由于错误的测量、错误的假设、错误的计算等产生的。同时RANSAC也假设，给定一组正确的数据，存在可以计算出符合这些数据的模型参数的方法。

优缺点：

RANSAC算法的优点是能鲁棒的估计模型参数。例如，他能从包含大量局外点的数据集中估计出高精度的参数。缺点是它计算参数的迭代次数没有上限，如果设置迭代次数的上限，得到的结果可能不是最优的结果，甚至可能得到错误的结果。RANSAC只有一定的概率得到的可信的模型，概率与迭代次数成正比。另一个缺点是它要求设置跟问题相关的阈值，RANSAC只能从特定的数据集中估计出一个模型，如果存在两个（或多个）模型，RANSAC不能找到别的模型。

## BA 

4. 描述BA

BA的本质是一个优化模型，其目的是最小化重投影/光度误差，用于优化相机位姿和世界点。局部BA用于优化局部的相机位姿，提高跟踪的精确度；全局BA用于全局过程中的相机位姿，使相机经过长时间、长距离的移动之后，相机位姿还比较准确。BA是一个图优化模型，一般选择LM(Levenberg-Marquardt)算法并在此基础上利用BA模型的稀疏性进行计算；可以直接计算，也可以使用g2o或者Ceres等优化库进行计算。

Bundle Adjustment : 从视觉重建中提炼出最优的3D模型和相机参数（内参和外参），好似每一个特征点都会反射几束光线，当把相机位姿和特征点位置做出最优的调整后，这些光线都收束到相机相机光心。也就是根据相机的投影模型构造构造代价函数，利用非线性优化（比如高斯牛顿或列文伯格马夸而尔特）来求最优解，利用雅克比矩阵的稀疏性解增量方程，得到相机位姿和特征点3D位置的最优解。

BA可以分为基于滤波器的BA和基于迭代的BA

5. 如何优化重投影误差？采用什么方法求解？如果误匹配的点重投影之后误差很大，如何解决它对整个优化问题的影响？
图优化模型，将路标点和相机位姿作为两个节点，观测模型作为边，同时优化两个变量

SLAM中常用L-M求解，如果误匹配误差很大可以考虑用核函数（Huber）


2. 重投影误差的表达式，误差关于位姿的偏导数怎么算？误差关于空间点的偏导数怎么计算？

## Filter

9. 卡尔曼滤波

预测：如何从上一时刻的状态，根据输入信息推断当前时刻的状态分布（先验）

计算协方差

更新：计算增益Kg，然后计算后验


5. EKF和BA的区别：

（1） EKF假设了马尔科夫性，认为k时刻的状态只与k-1时刻有关。非线性优化使用所有的历史数据，做全体的SLAM

（2） EKF做了线性化处理，在工作点处用一阶泰勒展开式近似整个函数，但在工作点较远处不一定成立。非线性优化每迭代一次，状态估计发生改变，我们会重新对新的估计点做 泰勒展开

可以把EKF看做只有一次迭代的BA

## G2O

3. g2o工程化的注意事项

图优化流程：

①选择节点和边，确定参数化形式

②加入节点和边

③选择初值，开始迭代

④计算J和H

⑤解H△x = -b

⑥GN/LM

g2o需要实现其中的③-⑥

g2o

①选择线性方程求解器（PCG/Cspare/Choldmod）

②选择一个blockslover

③选择迭代方式（GN/LM/Dogleg）

实现过程 ：选择节点和边

节点：g2o :: VertexSE3Expmap（相机位姿）

g2o :: VertexSBApointXYZ（路标）

边：g2o :: EdgeProjectXYZ2UV（重投影误差）

## Others

4. 做图优化时，对比采用四元数法和李代数法在数学直观性、计算量上的差异性


5. 优化求解过程中，g2o或者ceres的内部实现过程，有哪些加速计算的处理


6. 画后端优化因子图


7. 边缘化的过程全面分析，示意图，公式推导，优缺点，哪些矩阵块有改变


8. 10个相机同时看到100个路标点，问BA优化的雅克比矩阵多少维

2000*360

# MSF


12. 时间戳

工程目录下有GPS保存的坐标文件gps.txt和激光雷达保存的坐标文件laser.txt两个文件，两个文件的第一列为记录当前数据的时间戳，后两列为坐标。由于GPS每隔500时间单位保存一次数据，激光雷达每隔300时间单位保存一次数据，因此，一段时间内激光雷达保存的数据比GPS保存的数据要多。现在想取出两个文件中时间戳最接近的数据，并分别存放在gps2.txt和laser2.txt中，编写程序实现。（不知道哪位大神能讲下这道题。。。）

# SLAM

1. 描述特征点法和直接法的优缺点

特征点法

优点：

（1）精确，直接法属于强假设

（2）运动过大时，只要匹配点在像素内，则不太会引起误匹配，鲁棒性好

缺点：

（1）关键点提取、描述子、匹配耗时长

（2）特征点丢失场景无法使用

（3）只能构建稀疏地图

直接法

优点：

（1）省去计算特征点、描述子时间

（2）可以用在特征缺失的场合（比如白墙）

（3）可以构建半稠密乃至稠密地图

缺点：

（1）易受光照和模糊影响

（2）运动必须微小，要求相机运动较慢或采样频率较高（可以用图像金字塔改善）

（3）非凸性；单个像素没有区分度


2. 特征点法和直接法的BA有何不同

（1） 误差函数不同。特征点法是重投影误差，直接法是光度误差

（2） 雅克比矩阵不同


3. 光流和直接法有何不同：

光流仅估计了像素间的平移，但

（1）没有用相机结构

（2）没有考虑相机的旋转和图像缩放

（3）边界点追踪效果差


4. 特征匹配（稀疏）和稠密匹配区别

特征匹配：

（1）速度快，效率高，可以到亚像素级别，精度高

（2）匹配元素为物体的几何特征，对照明变化不敏感

稠密匹配

（1）速度慢，效率低

（2）对无纹理区域匹配效果不理想，对光强条件敏感


1. 如何对匹配好的点做进一步的处理，更好保证匹配效果

（1）确定匹配最大距离，汉明距离小于最小距离的两倍

（2）使用KNN-matching算法，令K=2。则每个match得到两个最接近的descriptor，然后计算最接近距离和次接近距离之间的比值，当比值大于既定值时，才作为最终match。

（3）RANSAC（使用RANSAC找到最佳单应性矩阵。由于这个函数使用的特征点同时包含正确和错误匹配点，因此计算的单应性矩阵依赖于二次投影的准确性）

8. 单目视觉slam中尺寸漂移是怎么产生的

单目相机根据一张图片无法得出一张图片中物体的实际大小，同理也就无法得出运动的尺度大小，这是产生尺度漂移的根源。而在优化过程中，单目相机使用对极几何中的三角测量原理，而三角测量中，极小的角度误差在累积之后深度不确定都会变得很大，从而无法保证尺度一致性。

6. 如何处理关键帧

关键帧选取的指标主要有：

（1）跟踪质量（主要根据跟踪过程中搜索到的点数和搜索的点数比例）/共视特征点

（2）距离最近关键帧的距离是否足够远（空间）/运动

（3）距离上一关键帧的帧数是否足够多（时间）

9. SLAM中的绑架问题

绑架问题就是重定位，是指机器人在缺少之前位置信息的情况下，如何去确定当前位姿。例如当机器人被安置在一个已经构建好地图的环境中，但是并不知道它在地图中的相对位置，或者在移动过程中，由于传感器的暂时性功能故障或相机的快速移动，都导致机器人先前的位置信息的丢失，在这种情况下如何重新确定自己的位置。

# ML/DL

# Others


你在ORB-SLAM项目中承担的角色以及做的贡献？
解释一下卡尔曼滤波？(没回答太好，但回答了基于滤波和基于优化的区别以及基于优化如何做)
相机和陀螺仪之间的外参如何标定？
ORB用什么方法提取角点和描述子？
提取特征点的方法有几种？分别说说
ORB中改进的FAST角点提取策略？(这里不是问FAST9的策略，他觉得这很基础)
你提到了四叉树原理，讲一下大概的步骤？
ORB提取不到特征点的地方怎么办？
解释一下VINS-Mono的初始化部分以及大致框架。(这个问题我回答得很乱，因为确实没有形成体系，所以我直说了我不太懂，这也为我后面进入第三轮埋下了伏笔)
我没问题了，你还有什么问题吗？(我认为这个问题非常重要，重要性完全不次于技术问题，后面面经会说)

第一家：盈迪曼德INDEMIND

问题：

PnP的原理是什么？它是从几D到几D的？
ORB-SLAM中的B是什么？如何得到的？
代码能力怎么样，自己写过工程吗？(工程实践能力确实很重要...可惜我也不多)
说说激光和视觉的区别？
IMU和陀螺仪的方差都怎么标定？
对IMU噪声有没有更好的处理办法？
你对滑动窗口的理解？
边缘化之后的矩阵变稀疏了吗？
你还有什么问题吗？能实习多久？


第二家：四维图新（点云方向）

问题：

自己实现过什么SLAM算法？说说实现的原理
SfM的原理和算法
BA的流程？
了解激光点云吗？激光和视觉的区别

-----

１. 连通区域算法（可以将 图像简化为二值图来考虑 http://blog.csdn.net/icvpr/article/details/10259577 ）

2. 实现RANSAC的框架（MRPT写得是比较好的，注意每次此迭代后需要更新

迭代次数。见libs/base/src/math/ransac.cpp）

3. Homography和Fundamentalmatrix的性质与区别

4. 简单实现cv::Mat()

5. 简述一下GN、LM等优化方法的区别

6. 推导一下卡尔曼滤波，描述一下粒子滤( http://blog.csdn.net/heyijia0327 ）

7. 描述一下SIFT或者SURF特征检测，匹配

8. 如何求解Ax=b (非迭代、迭代，其中非迭代的方法可以参考eigen手册，上面 列了一些 ( http://eigen.tuxfamily.org/dox/group__TutorialLinearAlgebra.html )

9. 简述一下Bundle Adjustment的过程

10. 对熟悉的某一个开源SLAM，简述其流程

-----